{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56c02a77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting NASA Team file list\n"
     ]
    }
   ],
   "source": [
    "# input parameters\n",
    "date_start: str = input(\"Enter starting date in format YYYY-MM-DD: \")\n",
    "date_end: str = input(\"Enter ending date in format YYYY-MM-DD: \")\n",
    "year = date_end[0:4]\n",
    "\n",
    "# import libraries\n",
    "\n",
    "import earthaccess\n",
    "import xarray as xr\n",
    "import dask\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import cartopy.feature as cfeature\n",
    "import cartopy.crs as ccrs\n",
    "from rasterio import features\n",
    "from scipy.ndimage import distance_transform_edt\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pyproj import Proj, Transformer\n",
    "from pathlib import Path\n",
    "import glob\n",
    "import re\n",
    "\n",
    "# colormap for plotting sea ice throughout rest of project\n",
    "\n",
    "cmap = plt.get_cmap(\"Blues_r\").copy()\n",
    "cmap.set_bad(color='lightgray')\n",
    "\n",
    "## PASSIVE MICROWAVE SECTION ##\n",
    "\n",
    "# authenticate NASA earth access\n",
    "print('Getting NASA Team file list')\n",
    "\n",
    "auth = earthaccess.login(strategy='interactive', persist = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4aafb39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c3292babfe14605b648659345bd3e60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "QUEUEING TASKS | :   0%|          | 0/347 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f1ca4480926476fb7b4865306e98f40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PROCESSING TASKS | :   0%|          | 0/347 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "324434553bb044a0b72cc08067325911",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "COLLECTING RESULTS | :   0%|          | 0/347 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting NASA Bootstrap file list\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01b6fd473735476c8ff6403e9b005b45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "QUEUEING TASKS | :   0%|          | 0/348 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a40ee52e05b4ee487a5d8c125a582ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PROCESSING TASKS | :   0%|          | 0/348 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e5470bacbaf4595a765958caa62abdb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "COLLECTING RESULTS | :   0%|          | 0/348 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# search NASA database for Team\n",
    "\n",
    "results = earthaccess.search_data(\n",
    "    short_name= 'NSIDC-0051',\n",
    "    temporal=(date_start, date_end),\n",
    "    bounding_box=(-180, 0, 180, 90),\n",
    "    cloud_hosted=True\n",
    ")\n",
    "\n",
    "filtered_results = [\n",
    "    g for g in results\n",
    "    if re.search(r'_20\\d{6}_', g.data_links(access='external')[0])\n",
    "]\n",
    "\n",
    "# get files from NSIDC\n",
    "\n",
    "files_team = earthaccess.open(filtered_results)\n",
    "\n",
    "# search NASA database for Bootstrap\n",
    "print('Getting NASA Bootstrap file list')\n",
    "\n",
    "results = earthaccess.search_data(\n",
    "    short_name= 'NSIDC-0079',\n",
    "    temporal=(date_start, date_end),\n",
    "    bounding_box=(-180, 0, 180, 90),\n",
    "    cloud_hosted=True\n",
    ")\n",
    "\n",
    "filtered_results = [\n",
    "    g for g in results\n",
    "    if re.search(r'_20\\d{6}_', g.data_links(access='external')[0])\n",
    "]\n",
    "\n",
    "# get files from NSIDC\n",
    "\n",
    "files_bootstrap = earthaccess.open(filtered_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c596ffe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening daily NASA Team data into array\n",
      "Opening daily NASA Bootstrap data into array\n"
     ]
    }
   ],
   "source": [
    "# stream team into xarray\n",
    "print('Opening daily NASA Team data into array')\n",
    "\n",
    "ds = xr.open_mfdataset(\n",
    "    files_team, \n",
    "    parallel = True, \n",
    "    concat_dim=\"time\", \n",
    "    combine=\"nested\", \n",
    "    data_vars='minimal', \n",
    "    coords='minimal', \n",
    "    compat='override'\n",
    ")\n",
    "\n",
    "# change ice concentration variable to something universal\n",
    "\n",
    "icecon_vars = sorted([var for var in ds.data_vars if 'ICECON'in var], reverse=True)\n",
    "icecon = ds[icecon_vars].to_array(\"source\").max(\"source\", skipna=True)\n",
    "\n",
    "# add back to dataset and clean up\n",
    "ds = ds.assign(team_icecon=icecon).drop_vars(icecon_vars)\n",
    "\n",
    "# stream bootstrap into xarray\n",
    "print('Opening daily NASA Bootstrap data into array')\n",
    "ds_bootstrap = xr.open_mfdataset(\n",
    "    files_bootstrap, \n",
    "    parallel = True, \n",
    "    concat_dim=\"time\", \n",
    "    combine=\"nested\", \n",
    "    data_vars='minimal', \n",
    "    coords='minimal', \n",
    "    compat='override'\n",
    ")\n",
    "\n",
    "# change ice concentration variable to something universal\n",
    "\n",
    "icecon_vars = sorted([var for var in ds_bootstrap.data_vars if 'ICECON'in var], reverse=True)\n",
    "icecon = ds_bootstrap[icecon_vars].to_array(\"source\").max(\"source\", skipna=True)\n",
    "\n",
    "# add back to dataset and clean up\n",
    "ds = ds.assign(bootstrap_icecon=icecon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18cdca2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in land file from geopandas and initialize transform (from NSIDC metadata)\n",
    "print('Calculating distance from land for each pixel')\n",
    "\n",
    "land = gpd.read_file(\"../data/ne_10m_land/ne_10m_land.shp\")\n",
    "land = land.to_crs(epsg=3411)\n",
    "transform = [25000, 0, -3837500, 0, -25000, 5837500]\n",
    "\n",
    "# use transform to mask out coastal cells\n",
    "\n",
    "land_mask = features.rasterize(\n",
    "    ((geom, 1) for geom in land.geometry),\n",
    "    out_shape=(448, 304),\n",
    "    transform=transform,\n",
    "    fill=0,\n",
    "    dtype=np.uint8\n",
    ")\n",
    "\n",
    "# calculate distance from land using euclidian distance transform\n",
    "\n",
    "distance_from_land = distance_transform_edt(land_mask == 0)\n",
    "\n",
    "# convert to xarray.DataArray\n",
    "\n",
    "distance_xr = xr.DataArray(\n",
    "    distance_from_land,\n",
    "    coords={'y': ds.y, 'x': ds.x},\n",
    "    dims=('y', 'x'),\n",
    "    name='distance_to_land_cells'\n",
    ")\n",
    "\n",
    "# add as data variable in ds\n",
    "\n",
    "ds['edtl'] = distance_xr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b1c0bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NEW — COULD BE BUGGY\n",
    "# resindex dataset\n",
    "\n",
    "nrows = ds.sizes['y']\n",
    "ncols = ds.sizes['x']\n",
    "\n",
    "ds = ds.assign_coords({\n",
    "    'row': ('y', np.arange(nrows)),\n",
    "    'col': ('x', np.arange(ncols))\n",
    "}).swap_dims({'y': 'row', 'x': 'col'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aade8fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## VISUAL ICE SECTION ##\n",
    "# create visual PANDAS DATAFRAME\n",
    "print('Reading in and engineering visual data')\n",
    "\n",
    "# read in files\n",
    "\n",
    "folderpath = '../local_data/visual_ice/'\n",
    "paths = Path(folderpath).glob(f'*{year}*.csv')\n",
    "pathlist = list(paths)\n",
    "\n",
    "# data cleaning of visual datasets\n",
    "\n",
    "visual = pd.concat(map(pd.read_csv, pathlist), ignore_index=True)\n",
    "\n",
    "# convert things for xarray\n",
    "\n",
    "visual[\"time\"] = pd.to_datetime(visual[\"Date\"], yearfirst=True)\n",
    "visual['row'] = visual['Row'] - 1\n",
    "visual['col'] = visual['Column'] - 1\n",
    "\n",
    "# drop duplicates\n",
    "\n",
    "visual = visual.drop_duplicates(subset=[\"time\", \"row\", \"col\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c321cf70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATE VISUAL ARRAY\n",
    "# convert to xarray\n",
    "\n",
    "da_sparse = visual.set_index(['time', 'row', 'col']).to_xarray()\n",
    "da_full = da_sparse.reindex_like(ds, method=None)\n",
    "\n",
    "da_full = da_full.chunk({'time': 2})\n",
    "ds = ds.assign(**{'visual_ice': da_full['SI frac']})\n",
    "\n",
    "# sanity check to make sure everything works\n",
    "\n",
    "col_min, col_max = visual['col'].min(), visual['col'].max()\n",
    "row_min, row_max = visual['row'].min(), visual['row'].max()\n",
    "\n",
    "ds_subset = ds.sel(col=slice(col_min, col_max), row=slice(row_min, row_max))\n",
    "ax = ds_subset.team_icecon.mean(dim='time').plot(\n",
    "    cmap=cmap,\n",
    "    figsize=(6,6)\n",
    ")\n",
    "\n",
    "plt.scatter(\n",
    "    visual['col'],\n",
    "    visual['row'],\n",
    "    color='black',\n",
    "    s=1,\n",
    "    alpha=0.6\n",
    ")\n",
    "plt.title(f\"Where we Have Visual Data in Year {year}\")\n",
    "plt.savefig(f'../figures/visual_data_extent/{year}_visual_extent.png')\n",
    "plt.close()\n",
    "\n",
    "# print dataset\n",
    "\n",
    "print('Printing dataset with visual, team, bootstrap, and distance from land')\n",
    "print(ds)\n",
    "\n",
    "## ERROR CALCULATIONS ##\n",
    "print('Starting error calculations')\n",
    "\n",
    "# ERROR FOR TEAM\n",
    "\n",
    "condition = ((ds.visual_ice.notnull()) & (ds.team_icecon < 1.001))\n",
    "ds_clean = ds.where(condition, other=np.nan).compute()\n",
    "\n",
    "# calc error\n",
    "\n",
    "error_team = (((ds_clean['team_icecon'] - ds_clean['visual_ice'])**2)**0.5)\n",
    "error_avg = error_team.mean(dim=['time', 'col', 'row'], skipna=True)\n",
    "print('RMS error for NASA Team is', error_avg.compute().item())\n",
    "\n",
    "# save a data cleaned pandas dataframe for team with everything (1.012 = coast, 1.016 = land)\n",
    "\n",
    "df = ds_clean.to_dataframe().reset_index().dropna()\n",
    "df.to_csv(f'../data/data_frames/team_validation_{year}.csv')\n",
    "\n",
    "# ERROR FOR BOOTSTRAP\n",
    "\n",
    "condition = ((ds.visual_ice.notnull()) & (ds.bootstrap_icecon < 1.001))\n",
    "ds_clean = ds.where(condition, other=np.nan).compute()\n",
    "\n",
    "# error calculation bootstrap\n",
    "\n",
    "error_bootstrap = (((ds_clean['bootstrap_icecon'] - ds_clean['visual_ice'])**2)**0.5)\n",
    "error_avg = error_bootstrap.mean(dim=['time', 'col', 'row'], skipna=True)\n",
    "print('RMS error for NASA Bootstrap is', error_avg.compute().item())\n",
    "\n",
    "# save a data cleaned pandas dataframe for boostrap with everything (1.012 = coast, 1.016 = land)\n",
    "\n",
    "df = ds_clean.to_dataframe().reset_index().dropna()\n",
    "df.to_csv(f'../data/data_frames/bootstrap_validation_{year}.csv')\n",
    "\n",
    "# MAP ERROR\n",
    "\n",
    "# map error NASA team\n",
    "\n",
    "sns.set_style('darkgrid')\n",
    "error_subset = error_team.sel(col=slice(col_min, col_max), row=slice(row_max, row_min))\n",
    "ax = error_subset.mean(dim='time', skipna=True).plot(cmap = 'RdBu', figsize=(6,6))\n",
    "plt.title(f\"Error Between NASA Team and Visual Mapped 2023-04-01 to 2023-05-31\")\n",
    "plt.savefig(f'../figures/error_maps/team_{year}_error.png')\n",
    "plt.close()\n",
    "\n",
    "# map error NASA bootstrap\n",
    "\n",
    "error_subset = error_bootstrap.sel(col=slice(col_min, col_max), row=slice(row_max, row_min))\n",
    "ax = error_subset.mean(dim='time', skipna=True).plot(cmap = 'RdBu', figsize=(6,6))\n",
    "plt.title(f\"Error Between NASA Team and Visual Mapped 2023-04-01 to 2023-05-31\")\n",
    "plt.savefig(f'../figures/error_maps/bootstrap_{year}_error.png')\n",
    "plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "coastal-ice",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
